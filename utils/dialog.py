import asyncio
import json
from datetime import datetime, date
import random
import openai
from aioredis import Redis
from loguru import logger

from config_reader import config
from utils.gspread_tools import gs_save_new_task

save_time_long = 60 * 60 * 2
redis = Redis(host='localhost', port=6379, db=6)
openai_key = config.openai_key.get_secret_value()


# https://dialogflow.cloud.google.com/#/editAgent/mtl-skynet-hldy/


async def save_to_redis(chat_id, msg, is_answer=False):
    data_name = f'{chat_id}:{round(datetime.now().timestamp())}'
    j = {"content": msg}
    if is_answer:
        j["role"] = "assistant"
    else:
        j["role"] = "user"
    await redis.set(data_name, json.dumps(j))
    await redis.expire(data_name, save_time_long)


async def load_from_redis(chat_id):
    keys = await redis.keys(f'{chat_id}:*')
    messages = []

    for key in keys:
        value = await redis.get(key)
        # –∏–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –∏ –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –≤ —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
        message = json.loads(value)
        # –∏–∑–≤–ª–µ–∫–∞–µ–º timestamp –∏–∑ –∫–ª—é—á–∞
        _, timestamp = key.decode().split(":")
        # –¥–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π timestamp –≤ —Å–ø–∏—Å–æ–∫
        messages.append((float(timestamp), message))

    # —Å–æ—Ä—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    messages.sort(key=lambda x: x[0])

    # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏—è, –±–µ–∑ timestamp
    return [msg for _, msg in messages]


async def delete_last_redis(chat_id):
    keys = await redis.keys(f'{chat_id}:*')

    if not keys:  # –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∫–ª—é—á–∏
        return

    # –ò–∑–≤–ª–µ–∫–∞–µ–º timestamp –∏–∑ –∫–∞–∂–¥–æ–≥–æ –∫–ª—é—á–∞ –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –∫–ª—é—á–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    keys.sort(key=lambda key: float(key.decode().split(":")[1]))

    # –£–¥–∞–ª—è–µ–º –∫–ª—é—á —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–∏ (—Ç.–µ. –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫–ª—é—á)
    await redis.delete(keys[-1])


async def talk(chat_id, msg):
    await save_to_redis(chat_id, msg)
    msg_data = await load_from_redis(chat_id)
    msg = await talk_open_ai_async(msg_data=msg_data)
    if msg:
        await save_to_redis(chat_id, msg, is_answer=True)
        return msg
    else:
        await delete_last_redis(chat_id)
        return '=( connection error, retry again )='


async def talk_open_ai_list_models():
    openai.organization = "org-Iq64OmMI81NWnwcPtn72dc7E"
    openai.api_key = openai_key
    # list models
    models = openai.Model.list()
    print(list(models))
    for raw in models['data']:
        if raw['id'].find('gpt') > -1:
            print(raw['id'])
    # print(raw)
    # gpt-3.5-turbo-0613
    # gpt-3.5-turbo-16k-0613
    # gpt-3.5-turbo-16k
    # gpt-3.5-turbo-0301
    # gpt-3.5-turbo


async def talk_open_ai_async(msg=None, msg_data=None, user_name=None, b16k=False):
    openai.organization = "org-Iq64OmMI81NWnwcPtn72dc7E"
    openai.api_key = openai_key
    # list models
    # models = openai.Model.list()

    if msg_data:
        messages = msg_data
    else:
        messages = [{"role": "user", "content": msg}]
        if user_name:
            messages[0]["name"] = user_name
    try:
        print('****', messages)
        if b16k:
            chat_completion_resp = await openai.ChatCompletion.acreate(model="gpt-4", messages=messages)
        else:
            chat_completion_resp = await openai.ChatCompletion.acreate(model="gpt-3.5-turbo", messages=messages)
        return chat_completion_resp.choices[0].message.content
    except openai.error.APIError as e:
        logger.info(e.code)
        logger.info(e.args)
        return None


async def talk_get_comment(chat_id, article):
    messages = [{"role": "system",
                 "content": "–ù–∞–ø–∏—à–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫ —Å—Ç–∞—Ç—å–µ, —Ç—ã —Å—Ç–æ—Ä–æ–Ω–Ω–∏–∫ –ª–∏–±–µ—Ä—Ç–∞—Ä–∏–∞–Ω—Å—Ç–≤–∞. –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø—Ä–∏–∫–æ–ª—å–Ω—ã–π, –¥—Ä—É–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π, –Ω–µ –±–æ–ª–µ–µ 300 —Å–∏–º–≤–æ–ª–æ–≤. –ù–µ —É–∫–∞–∑—ã–≤–∞–π, —á—Ç–æ —ç—Ç–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∏–ª–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –µ–≥–æ. –ù–∞–ø–∏—à–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å—Ä–∞–∑—É, –±–µ–∑ –≤–≤–µ–¥–µ–Ω–∏—è –∏–ª–∏ –∑–∞–∫–ª—é—á–µ–Ω–∏—è. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –∫–∞–≤—ã—á–∫–∏ –≤ –æ—Ç–≤–µ—Ç–µ. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ö–µ—à—Ç–µ–≥–∏ # –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö !"},
                {"role": "user", "content": article}]
    await save_to_redis(chat_id, article)
    msg = await talk_open_ai_async(msg_data=messages)
    if msg:
        await save_to_redis(chat_id, msg, is_answer=True)
        return msg
    else:
        await delete_last_redis(chat_id)
        return '=( connection error, retry again )='


gor = (
    ("–û–≤–µ–Ω", "–¢–µ–ª–µ—Ü", "–ë–ª–∏–∑–Ω–µ—Ü—ã", "–†–∞–∫", "–õ–µ–≤", "–î–µ–≤–∞", "–í–µ—Å—ã", "–°–∫–æ—Ä–ø–∏–æ–Ω", "–°—Ç—Ä–µ–ª–µ—Ü", "–ö–æ–∑–µ—Ä–æ–≥", "–í–æ–¥–æ–ª–µ–π", "–†—ã–±—ã"),
    ("–†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –∑–≤–µ–∑–¥ ", "–†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –ø–ª–∞–Ω–µ—Ç ", "–ú–∞—Ä—Å ", "–í–µ–Ω–µ—Ä–∞ ", "–õ—É–Ω–∞ ", "–ú–ª–µ—á–Ω—ã–π –ø—É—Ç—å ", "–ê—Å—Ç—Ä–∞–ª—å–Ω—ã–µ –∫–∞—Ä—Ç–∞ ",
     "–Æ–ø–∏—Ç–µ—Ä ", "–ü–ª—É—Ç–æ–Ω ", "–°–∞—Ç—É—Ä–Ω ",),
    ("–≥–æ–≤–æ—Ä–∏—Ç –≤–∞–º ", "—Å–æ–≤–µ—Ç—É–µ—Ç –≤–∞–º ", "–ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –≤–∞–º ", "–ø—Ä–µ–¥—Ä–µ–∫–∞–µ—Ç –≤–∞–º ", "–±–ª–∞–≥–æ–≤–æ–ª–∏—Ç –≤–∞—Å ", "—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç –≤–∞–º ",
     "–æ—á–µ–Ω—å —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç –≤–∞–º ", "–Ω–∞–º–µ–∫–∞–µ—Ç –≤–∞–º ", "—Ç—Ä–µ–±—É–µ—Ç –æ—Ç –≤–∞—Å ",),
    ("–≤—ã–ø–∏—Ç—å –ø–∏–≤–∞", "–Ω–∞–ø–∏—Ç—å—Å—è –≤ —Ö–ª–∞–º", "–≤—ã–ø–∏—Ç—å –Ω–∏–∫—à–µ—á–∫–æ", "–≤—ã–ø–∏—Ç—å –Ω–µ—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –Ω–∏–∫—à–µ—á–∫–æ", "–≤—ã–ø–∏—Ç—å —Ç–µ–º–Ω–æ–≥–æ –Ω–∏–∫—à–µ—á–∫–æ",
     "–≤—ã–ø—ã—Ç—å —Ö—É–≥–∞—Ä–¥–µ–Ω–∞", "—Å–µ–≥–æ–¥–Ω—è –Ω–µ –ø–∏—Ç—å =(", "—Ö–æ—Ä–æ—à–æ –ø—Ä–∏–≥–ª—è–¥—ã–≤–∞—Ç—å –∑–∞ –æ—Ä–µ—à–∫–∞–º–∏", "–≤—ã–ø–∏—Ç—å —á–µ–≥–æ –ø–æ –∫—Ä–µ–ø—á–µ",
     "–ø–∏—Ç—å —Å–µ–≥–æ–¥–Ω—è —Å —Ö–æ—Ä–æ—à–µ–π –∑–∞–∫—É—Å–∫–æ–π", "–ø–æ–±–µ—Ä–µ—á—å –ø–µ—á–µ–Ω—å", "–Ω–∞–≥—Ä—É–∑–∏—Ç—å –ø–µ—á–µ–Ω—å", "–≤—ã–ø–∏—Ç—å —Ä–∞–∫–∏–∏", "–≤—ã–ø–∏—Ç—å –¥—É–Ω—å–∫–∏",
     "–≤—ã–ø–∏—Ç—å –ª–æ–∑—ã", "–≤—ã–ø–∏—Ç—å –∫–∞—Å–ø–∏–∏", "—Å–æ–æ–±—Ä–∞–∑–∏—Ç—å –Ω–∞ —Ç—Ä–æ–∏—Ö",)
)

lang_dict = {}


def get_horoscope() -> list:
    if date.today() == lang_dict.get('horoscope_date'):
        return lang_dict.get('horoscope', ['–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ =('])
    else:
        today_dic = [""]
        s3 = ""
        lang_dict['horoscope_date'] = date.today()
        horoscope = ["–ì–æ—Ä–æ—Å–∫–æ–ø –Ω–∞ —Å–µ–≥–æ–¥–Ω—è"]
        for s in gor[0]:
            horoscope.append(f'**{s}**')
            while s3 in today_dic:
                s3 = random.choice(gor[3])
            today_dic.append(s3)

            g = (random.choice(gor[1]) + random.choice(gor[2]) + s3)
            while g in horoscope:
                g = (random.choice(gor[1]) + random.choice(gor[2]) + s3)
            horoscope.append(g)

        horoscope.append("")
        horoscope.append("–ñ–µ–ª–∞—é –≤—Å–µ–º —Ö–æ—Ä–æ—à–µ–≥–æ –¥–Ω—è! üç∫üç∫üç∫")
        lang_dict['horoscope'] = horoscope
        return horoscope


async def talk_check_spam(article):
    messages = [{"role": "system",
                 "content": "–í—ã —è–≤–ª—è–µ—Ç–µ—Å—å –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–º—Å—è –Ω–∞ –≤—ã—è–≤–ª–µ–Ω–∏–∏ —Å–ø–∞–º–∞ –≤ –æ–±—ä—è–≤–ª–µ–Ω–∏—è—Ö. –í–∞—à–∞ –∑–∞–¥–∞—á–∞ - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —è–≤–ª—è—é—Ç—Å—è –ª–∏ –æ–Ω–∏ —Å–ø–∞–º–æ–º. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ —Å–≤–æ–π –æ—Ç–≤–µ—Ç –≤ –≤–∏–¥–µ –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏, —á—Ç–æ –¥–∞–Ω–Ω–æ–µ –æ–±—ä—è–≤–ª–µ–Ω–∏–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ø–∞–º–æ–º. –í–∞—à–∞ –æ—Ü–µ–Ω–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤—ã—Ä–∞–∂–µ–Ω–∞ –≤ —á–∏—Å–ª–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –Ω–∞–ø—Ä–∏–º–µ—Ä, 70.0 –¥–ª—è 70% –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏. –ù–∏–∫–∞–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞, —Ç–æ–ª—å–∫–æ 2 —Ü–∏—Ñ—Ä—ã. –í–µ—Ä–Ω–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª–∏–Ω–æ–π –≤ 2 —Å–∏–º–≤–æ–ª–∞."},
                {"role": "user", "content": article}]
    msg = None
    while msg is None:
        msg = await talk_open_ai_async(msg_data=messages)
        if not msg:
            await asyncio.sleep(1)
        if len(msg) > 3:
            logger.info(msg)
            msg = None
    return float(msg)


async def add_task_to_google(msg):
    # https://platform.openai.com/docs/guides/gpt/function-calling
    # Step 1: send the conversation and available functions to GPT
    openai.organization = "org-Iq64OmMI81NWnwcPtn72dc7E"
    openai.api_key = openai_key

    messages = [{"role": "user", "content": msg}]
    #async def gs_save_new_task(task_name, customer, manager, executor, contract_url):
    functions = [
        {
            "name": "gs_save_new_task",
            "description": "–î–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–¥–∞—á—É –≤ —Ç–∞–±–ª–∏—Ü—É –∑–∞–¥–∞—á",
            "parameters": {
                "type": "object",
                "properties": {
                    "task_name": {
                        "type": "string",
                        "description": "–û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏",
                    },
                    "customer": {
                        "type": "string",
                        "description": "–ó–∞–∫–∞–∑—á–∏–∫, –º–æ–∂–µ—Ç –±—ã—Ç—å None",
                    },
                    "manager": {
                        "type": "string",
                        "description": "–ú–µ–Ω–µ–¥–∂–µ—Ä –∑–∞–¥–∞—á–∏, –º–æ–∂–µ—Ç –±—ã—Ç—å None",
                    },
                    "executor": {
                        "type": "string",
                        "description": "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∫–æ—Ç–æ—Ä—ã–π –¥–∞–µ—Ç –∑–∞–¥–∞—á—É",
                    },
                    "contract_url": {
                        "type": "string",
                        "description": "–°—Å—ã–ª–∫–∞ –Ω–∞ –∑–∞–¥–∞—á—É, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—Å—ã–ª–∫–∞ –Ω–∞ –ø—Ä–æ—à–ª–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ",
                    },
                    #"unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                },
                "required": ["task_name", "executor", "contract_url"],
            },
        }
    ]
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo-0613",
        messages=messages,
        functions=functions,
        function_call="auto",  # auto is default, but we'll be explicit
    )
    response_message = response["choices"][0]["message"]

    # Step 2: check if GPT wanted to call a function
    if response_message.get("function_call"):
        # Step 3: call the function
        # Note: the JSON response may not always be valid; be sure to handle errors
        available_functions = {
            "gs_save_new_task": gs_save_new_task,
        }  # only one function in this example, but you can have multiple
        function_name = response_message["function_call"]["name"]
        function_to_call = available_functions[function_name]
        function_args = json.loads(response_message["function_call"]["arguments"])
        # async def gs_save_new_task(task_name, customer, manager, executor, contract_url):
        function_response = await function_to_call(
            task_name=function_args.get("task_name"),
            customer=function_args.get("customer"),
            manager=function_args.get("manager"),
            executor=function_args.get("executor"),
            contract_url=function_args.get("contract_url"),
        )

        # Step 4: send the info on the function call and function response to GPT
        messages.append(response_message)  # extend conversation with assistant's reply
        messages.append(
            {
                "role": "function",
                "name": function_name,
                "content": function_response,
            }
        )  # extend conversation with function response
        second_response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo-0613",
            messages=messages,
        )  # get a new response from GPT where it can see the function response
        return second_response.choices[0].message.content


async def talk_get_summary(article):
    messages = [{"role": "system",
                 "content": "–í—ã —è–≤–ª—è–µ—Ç–µ—Å—å –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–º—Å—è –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ —Ç–µ–∫—Å—Ç–æ–≤. –í–∞—à–∞ –∑–∞–¥–∞—á–∞ - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —á–∞—Ç–∞ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –∫—Ä–∞—Ç–∫–∏–π –æ–±–∑–æ—Ä –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è."},
                {"role": "user", "content": article}]
    msg = None
    while msg is None:
        msg = await talk_open_ai_async(msg_data=messages, b16k=True)
        if not msg:
            logger.info('msg is None')
            await asyncio.sleep(3)
    return msg


if __name__ == "__main__":
    pass
    #print(asyncio.run(add_task_to_google('–°–∫–∞–π–Ω–µ—Ç, –∑–∞–¥–∞—á–∞. –î–æ–±–∞–≤—å –∑–∞–¥–∞—á—É , –∑–∞–∫–∞–∑—á–∏–∫ —ç–Ω–∏, —Å—Å—ã–ª–∫–∞ ya.ru , –æ–ø–∏—Å–∞–Ω–∏–µ "–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ –ø–æ–ª—è –≤ –æ—Ç—á–µ—Ç"')))
    #asyncio.run(talk_open_ai_list_models())
    #exit()

    # article  = '''–ø—Ä–∏–≤–µ—Ç, –∏—â—É –≥–¥–µ –∫—É–ø–∏—Ç—å –º—ã–ª–æ '''
    # print(asyncio.run(talk_check_spam(article)))
    #print(asyncio.run(talk(0,'–†–∞—Å—Å–∫–∞–∂–∏ —Å–∫–∞–∑–∫—É –ø—Ä–æ –∫–æ–ª–æ–±–∫–∞ –Ω–∞ 10000 –∑–Ω–∞–∫–æ–≤')))
    asyncio.run(asyncio.sleep(50))
    print(asyncio.run(talk_open_ai_async('–†–∞—Å—Å–∫–∞–∂–∏ —Å–∫–∞–∑–∫—É –ø—Ä–æ –∫–æ–ª–æ–±–∫–∞ –Ω–∞ 10000 –∑–Ω–∞–∫–æ–≤', b16k=True)))
