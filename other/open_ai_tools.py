import asyncio
import json
import random
from datetime import datetime, date
import tiktoken
from redis.asyncio import Redis
from loguru import logger
from openai import AsyncOpenAI
from other.config_reader import config
from other.gspread_tools import gs_save_new_task

MAX_TOKENS = 4000
save_time_long = 60 * 60 * 2
redis = Redis.from_url(config.redis_url)
openai_key = config.openai_key.get_secret_value()
enc = tiktoken.encoding_for_model("gpt-3.5-turbo")

# client = OpenAI(api_key=openai_key)
aclient = AsyncOpenAI(api_key=openai_key,
                      base_url="https://openrouter.ai/api/v1",
                      )

extra_headers = {
    "HTTP-Referer": 'https://montelibero.org',  # Optional, for including your app on openrouter.ai rankings.
    "X-Title": 'Montelibero Bot',  # Optional. Shows in rankings on openrouter.ai.
}


# https://dialogflow.cloud.google.com/#/editAgent/mtl-skynet-hldy/

async def save_to_redis(chat_id, msg, is_answer=False):
    data_name = f'{chat_id}:{round(datetime.now().timestamp())}'
    j = {"content": msg}
    if is_answer:
        j["role"] = "assistant"
    else:
        j["role"] = "user"
    await redis.set(data_name, json.dumps(j))
    await redis.expire(data_name, save_time_long)


def num_tokens_from_messages(messages, model="gpt-3.5-turbo"):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Å–ø–∏—Å–∫–æ–º —Å–æ–æ–±—â–µ–Ω–∏–π."""
    try:
        encoding = tiktoken.encoding_for_model(model)
    except KeyError:
        print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞ cl100k_base.")
        encoding = tiktoken.get_encoding("cl100k_base")

    if "gpt-3.5-turbo" in model or "gpt-4" in model:
        # –î–ª—è –º–æ–¥–µ–ª–µ–π gpt-3.5-turbo –∏ gpt-4
        tokens_per_message = 3
        tokens_per_name = 1
    else:
        raise NotImplementedError(
            f"""num_tokens_from_messages() –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –¥–ª—è –º–æ–¥–µ–ª–∏ {model}. –°–º. https://github.com/openai/openai-python/blob/main/chatml.md –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ç–æ–∫–µ–Ω—ã."""
        )

    num_tokens = 0
    for message in messages:
        num_tokens += tokens_per_message
        for key, value in message.items():
            num_tokens += len(encoding.encode(value))
            if key == "name":
                num_tokens += tokens_per_name

    num_tokens += 3  # –∫–∞–∂–¥—ã–π –æ—Ç–≤–µ—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 'assistant'
    return num_tokens


async def load_from_redis(chat_id):
    keys = await redis.keys(f'{chat_id}:*')
    messages = []

    for key in keys:
        value = await redis.get(key)
        message = json.loads(value)
        _, timestamp = key.decode().split(":")
        messages.append((float(timestamp), message))

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–æ—Ç —Å–∞–º—ã—Ö —Å—Ç–∞—Ä—ã—Ö –∫ —Å–∞–º—ã–º –Ω–æ–≤—ã–º)
    messages.sort(key=lambda x: x[0])

    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã
    model = "gpt-3.5-turbo"  # –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
    formatted_messages = [msg[1] for msg in messages]  # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤
    total_tokens = num_tokens_from_messages(formatted_messages, model=model)
    logger.info(f"Total tokens: {total_tokens}")

    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –µ—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    while total_tokens > MAX_TOKENS and messages:
        removed_message = messages.pop(0)
        total_tokens = num_tokens_from_messages([msg[1] for msg in messages], model=model)
        logger.info(f"Total tokens after removing: {total_tokens}")

    return [msg[1] for msg in messages]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏–π


async def delete_last_redis(chat_id):
    keys = await redis.keys(f'{chat_id}:*')

    if not keys:  # –ø—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∫–ª—é—á–∏
        return

    # –ò–∑–≤–ª–µ–∫–∞–µ–º timestamp –∏–∑ –∫–∞–∂–¥–æ–≥–æ –∫–ª—é—á–∞ –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –∫–ª—é—á–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    keys.sort(key=lambda key: float(key.decode().split(":")[1]))

    # –£–¥–∞–ª—è–µ–º –∫–ª—é—á —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–∏ (—Ç.–µ. –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫–ª—é—á)
    await redis.delete(keys[-1])


async def talk(chat_id, msg, gpt4=False, googleit=False):
    await save_to_redis(chat_id, msg)
    if gpt4:
        msg = f"–¢–µ–±—è –∑–æ–≤—É—Ç –°–∫–∞–π–Ω–µ—Ç. –¢—ã –¥–æ–ª–∂–Ω–∞ –æ—Ç–≤–µ—á–∞—Ç—å –≤ –∂–µ–Ω—Å–∫–æ–º —Ä–æ–¥–µ.\n\n{msg}"
        msg = await talk_open_ai_async(msg=msg, gpt4=True, googleit=googleit)
    else:
        msg_data = await load_from_redis(chat_id)
        msg_data.insert(0, {"role": "system", "content": "–¢–µ–±—è –∑–æ–≤—É—Ç –°–∫–∞–π–Ω–µ—Ç. –¢—ã –¥–æ–ª–∂–Ω–∞ –æ—Ç–≤–µ—á–∞—Ç—å –≤ –∂–µ–Ω—Å–∫–æ–º —Ä–æ–¥–µ."})
        msg = await talk_open_ai_async(msg_data=msg_data, googleit=googleit)
    if msg:
        await save_to_redis(chat_id, msg, is_answer=True)
        return msg
    else:
        await delete_last_redis(chat_id)
        return '=( connection error, retry again )='


async def talk_open_ai_list_models(name_filter):
    # list models
    models = await aclient.models.list()
    # print(models, type(models))
    for raw in models.data:
        if raw.id.find(name_filter) > -1:
            print(raw.id)


async def talk_open_ai_async(msg=None, msg_data=None, user_name=None, gpt4=False, googleit: bool = False):
    addons = ":online" if googleit else ""
    if msg_data:
        messages = msg_data
    else:
        messages = [{"role": "user", "content": msg}]
        if user_name:
            messages[0]["name"] = user_name
    try:
        if gpt4:
            chat_completion_resp = await aclient.chat.completions.create(model=f"gpt-4", messages=messages, extra_headers=extra_headers)
        else:
            chat_completion_resp = await aclient.chat.completions.create(model=f"gpt-4o{addons}", messages=messages, extra_headers=extra_headers)

        return chat_completion_resp.choices[0].message.content
    except Exception as e:
        logger.info(e.args)
        return None


async def talk_get_comment(chat_id, article):
    messages = [{"role": "system",
                 "content": "–ù–∞–ø–∏—à–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫ —Å—Ç–∞—Ç—å–µ, —Ç—ã —Å—Ç–æ—Ä–æ–Ω–Ω–∏–∫ –ª–∏–±–µ—Ä—Ç–∞—Ä–∏–∞–Ω—Å—Ç–≤–∞. –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø—Ä–∏–∫–æ–ª—å–Ω—ã–π, –¥—Ä—É–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π, –Ω–µ –±–æ–ª–µ–µ 300 —Å–∏–º–≤–æ–ª–æ–≤. –ù–µ —É–∫–∞–∑—ã–≤–∞–π, —á—Ç–æ —ç—Ç–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∏–ª–∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –µ–≥–æ. –ù–∞–ø–∏—à–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å—Ä–∞–∑—É, –±–µ–∑ –≤–≤–µ–¥–µ–Ω–∏—è –∏–ª–∏ –∑–∞–∫–ª—é—á–µ–Ω–∏—è. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –∫–∞–≤—ã—á–∫–∏ –≤ –æ—Ç–≤–µ—Ç–µ. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Ö–µ—à—Ç–µ–≥–∏ # –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö !"},
                {"role": "user", "content": article}]
    await save_to_redis(chat_id, article)
    msg = await talk_open_ai_async(msg_data=messages)
    if msg:
        await save_to_redis(chat_id, msg, is_answer=True)
        return msg
    else:
        await delete_last_redis(chat_id)
        return '=( connection error, retry again )='


gor = (
    ("–û–≤–µ–Ω", "–¢–µ–ª–µ—Ü", "–ë–ª–∏–∑–Ω–µ—Ü—ã", "–†–∞–∫", "–õ–µ–≤", "–î–µ–≤–∞", "–í–µ—Å—ã", "–°–∫–æ—Ä–ø–∏–æ–Ω", "–°—Ç—Ä–µ–ª–µ—Ü", "–ö–æ–∑–µ—Ä–æ–≥", "–í–æ–¥–æ–ª–µ–π", "–†—ã–±—ã"),
    ("–†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –∑–≤–µ–∑–¥ ", "–†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –ø–ª–∞–Ω–µ—Ç ", "–ú–∞—Ä—Å ", "–í–µ–Ω–µ—Ä–∞ ", "–õ—É–Ω–∞ ", "–ú–ª–µ—á–Ω—ã–π –ø—É—Ç—å ", "–ê—Å—Ç—Ä–∞–ª—å–Ω—ã–µ –∫–∞—Ä—Ç–∞ ",
     "–Æ–ø–∏—Ç–µ—Ä ", "–ü–ª—É—Ç–æ–Ω ", "–°–∞—Ç—É—Ä–Ω ",),
    ("–≥–æ–≤–æ—Ä–∏—Ç –≤–∞–º ", "—Å–æ–≤–µ—Ç—É–µ—Ç –≤–∞–º ", "–ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –≤–∞–º ", "–ø—Ä–µ–¥—Ä–µ–∫–∞–µ—Ç –≤–∞–º ", "–±–ª–∞–≥–æ–≤–æ–ª–∏—Ç –≤–∞—Å ", "—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç –≤–∞–º ",
     "–æ—á–µ–Ω—å —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç –≤–∞–º ", "–Ω–∞–º–µ–∫–∞–µ—Ç –≤–∞–º ", "—Ç—Ä–µ–±—É–µ—Ç –æ—Ç –≤–∞—Å ",),
    ("–≤—ã–ø–∏—Ç—å –ø–∏–≤–∞", "–Ω–∞–ø–∏—Ç—å—Å—è –≤ —Ö–ª–∞–º", "–≤—ã–ø–∏—Ç—å –Ω–∏–∫—à–µ—á–∫–æ", "–≤—ã–ø–∏—Ç—å –Ω–µ—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –Ω–∏–∫—à–µ—á–∫–æ", "–≤—ã–ø–∏—Ç—å —Ç–µ–º–Ω–æ–≥–æ –Ω–∏–∫—à–µ—á–∫–æ",
     "–≤—ã–ø—ã—Ç—å —Ö—É–≥–∞—Ä–¥–µ–Ω–∞", "—Å–µ–≥–æ–¥–Ω—è –Ω–µ –ø–∏—Ç—å =(", "—Ö–æ—Ä–æ—à–æ –ø—Ä–∏–≥–ª—è–¥—ã–≤–∞—Ç—å –∑–∞ –æ—Ä–µ—à–∫–∞–º–∏", "–≤—ã–ø–∏—Ç—å —á–µ–≥–æ –ø–æ –∫—Ä–µ–ø—á–µ",
     "–ø–∏—Ç—å —Å–µ–≥–æ–¥–Ω—è —Å —Ö–æ—Ä–æ—à–µ–π –∑–∞–∫—É—Å–∫–æ–π", "–ø–æ–±–µ—Ä–µ—á—å –ø–µ—á–µ–Ω—å", "–Ω–∞–≥—Ä—É–∑–∏—Ç—å –ø–µ—á–µ–Ω—å", "–≤—ã–ø–∏—Ç—å —Ä–∞–∫–∏–∏", "–≤—ã–ø–∏—Ç—å –¥—É–Ω—å–∫–∏",
     "–≤—ã–ø–∏—Ç—å –ª–æ–∑—ã", "–≤—ã–ø–∏—Ç—å –∫–∞—Å–ø–∏–∏", "—Å–æ–æ–±—Ä–∞–∑–∏—Ç—å –Ω–∞ —Ç—Ä–æ–∏—Ö",)
)

lang_dict = {}


def get_horoscope() -> list:
    if date.today() == lang_dict.get('horoscope_date'):
        return lang_dict.get('horoscope', ['–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ =('])
    else:
        today_dic = [""]
        s3 = ""
        lang_dict['horoscope_date'] = date.today()
        horoscope = ["–ì–æ—Ä–æ—Å–∫–æ–ø –Ω–∞ —Å–µ–≥–æ–¥–Ω—è"]
        for s in gor[0]:
            horoscope.append(f'**{s}**')
            while s3 in today_dic:
                s3 = random.choice(gor[3])
            today_dic.append(s3)

            g = (random.choice(gor[1]) + random.choice(gor[2]) + s3)
            while g in horoscope:
                g = (random.choice(gor[1]) + random.choice(gor[2]) + s3)
            horoscope.append(g)

        horoscope.append("")
        horoscope.append("–ñ–µ–ª–∞—é –≤—Å–µ–º —Ö–æ—Ä–æ—à–µ–≥–æ –¥–Ω—è! üç∫üç∫üç∫")
        lang_dict['horoscope'] = horoscope
        return horoscope


async def talk_check_spam(article):
    messages = [
        {"role": "system",
         "content": "–í—ã —è–≤–ª—è–µ—Ç–µ—Å—å –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–º—Å—è –Ω–∞ –≤—ã—è–≤–ª–µ–Ω–∏–∏ —Å–ø–∞–º–∞ –≤ –æ–±—ä—è–≤–ª–µ–Ω–∏—è—Ö. "
                    "–í–∞—à–∞ –∑–∞–¥–∞—á–∞ - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —è–≤–ª—è—é—Ç—Å—è –ª–∏ –æ–Ω–∏ —Å–ø–∞–º–æ–º. "
                    "—Ç.–µ. –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç –ª–∏ —á—Ç–æ-—Ç–æ –∫—É–ø–∏—Ç—å, –∏–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∑–∞—Ä–∞–±–æ—Ç–∫–∞ –∏–ª–∏ –Ω–∞–ø–∏—Å–∞—Ç—å –≤ –ª–∏—á–∫—É –ø–æ –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É. "
                    "–ï—Å–ª–∏ –≥–æ–≤–æ—Ä—è—Ç —á—Ç–æ-—Ç–æ –ø—Ä–æ —á–µ—Ä–Ω–æ–≥–æ—Ä–∏—é, –ë—É–¥–≤—É, –ë–∞—Ä, –ü–æ–¥–≥–æ—Ä–∏—Ü—É –∏–ª–∏ EURMTL —Ç–æ —ç—Ç–æ –Ω–µ —Å–ø–∞–º "
                    "–ï—Å–ª–∏ —Ö–æ—Ç—è—Ç –æ–±–º–µ–Ω—è—Ç—å –¥–µ–Ω—å–≥–∏ –∏ –≤–µ–∂–ª–∏–≤–æ –æ–±—Ä–∞—â–∞—é—Ç—Å—è –±–µ–∑ —Å—Å—ã–ª–æ–∫ –∏ –∑–∞–∑—ã–≤–∞–Ω–∏—è –≤ –õ–° —Ç–æ —Ç–æ–∂–µ –Ω–µ —Å–ø–∞–º."
                    "–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ —Å–≤–æ–π –æ—Ç–≤–µ—Ç –≤ –≤–∏–¥–µ JSON —Å –∫–ª—é—á–æ–º 'spam_probability' –∏ –∑–Ω–∞—á–µ–Ω–∏–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö, "
                    "–Ω–∞–ø—Ä–∏–º–µ—Ä, {\"spam_probability\": 70}."},
        {"role": "user", "content": article}
    ]

    msg = None
    while msg is None:
        msg = await talk_open_ai_async(msg_data=messages)
        if not msg:
            await asyncio.sleep(1)
        try:
            # –ü–æ–ø—ã—Ç–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫—É –≤ JSON
            result = json.loads(msg)
            if 'spam_probability' in result:
                return int(result['spam_probability'])
            else:
                msg = None  # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Ü–∏–∫–ª–∞, –µ—Å–ª–∏ –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω
        except json.JSONDecodeError:
            msg = None  # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Ü–∏–∫–ª–∞, –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è JSON


async def add_task_to_google(msg):
    # https://platform.openai.com/docs/guides/gpt/function-calling
    model = "gpt-4-turbo-preview"

    messages = [{"role": "user", "content": msg}]
    # async def gs_save_new_task(task_name, customer, manager, executor, contract_url):
    functions = [
        {
            "name": "gs_save_new_task",
            "description": "–î–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–¥–∞—á—É –≤ —Ç–∞–±–ª–∏—Ü—É –∑–∞–¥–∞—á",
            "parameters": {
                "type": "object",
                "properties": {
                    "task_name": {
                        "type": "string",
                        "description": "–û–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏",
                    },
                    "customer": {
                        "type": "string",
                        "description": "–ó–∞–∫–∞–∑—á–∏–∫, –º–æ–∂–µ—Ç –±—ã—Ç—å None",
                    },
                    "manager": {
                        "type": "string",
                        "description": "–ú–µ–Ω–µ–¥–∂–µ—Ä –∑–∞–¥–∞—á–∏, –º–æ–∂–µ—Ç –±—ã—Ç—å None",
                    },
                    "executor": {
                        "type": "string",
                        "description": "–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∞–≤—Ç–æ—Ä –≤—Ç–æ—Ä–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –µ—Å–ª–∏ –Ω–µ—Ç –¥—Ä—É–≥–æ–≥–æ –≤ —Ç–µ–∫—Å—Ç–µ",
                    },
                    "contract_url": {
                        "type": "string",
                        "description": "–°—Å—ã–ª–∫–∞ –Ω–∞ –∑–∞–¥–∞—á—É, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—Å—ã–ª–∫–∞ –Ω–∞ –ø–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ",
                    },
                    # "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                },
                "required": ["task_name", "executor", "contract_url"],
            },
        }
    ]
    response = await aclient.chat.completions.create(model=model,
                                                     messages=messages,
                                                     extra_headers=extra_headers,
                                                     functions=functions,
                                                     function_call="auto")
    response_message = response.choices[0].message

    # Step 2: check if GPT wanted to call a function
    if response_message.function_call:
        # Step 3: call the function
        # Note: the JSON response may not always be valid; be sure to handle errors
        available_functions = {
            "gs_save_new_task": gs_save_new_task,
        }  # only one function in this example, but you can have multiple
        function_name = response_message.function_call.name
        function_to_call = available_functions[function_name]
        function_args = json.loads(response_message.function_call.arguments)
        # async def gs_save_new_task(task_name, customer, manager, executor, contract_url):
        function_response = await function_to_call(
            task_name=function_args.get("task_name"),
            customer=function_args.get("customer"),
            manager=function_args.get("manager"),
            executor=function_args.get("executor"),
            contract_url=function_args.get("contract_url"),
        )

        # Step 4: send the info on the function call and function response to GPT
        messages.append(response_message)  # extend conversation with assistant's reply
        messages.append(
            {
                "role": "function",
                "name": function_name,
                "content": function_response,
            }
        )  # extend conversation with function response
        messages.append({
            "role": "system",
            "content": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏–∑–±–µ–≥–∞–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å—Å—ã–ª–æ–∫ –≤ –≤–∞—à–µ–º –æ—Ç–≤–µ—Ç–µ."
        })
        second_response = await aclient.chat.completions.create(model=model,
                                                                extra_headers=extra_headers,
                                                                messages=messages)  # get a new response from GPT where it can see the function response
        return second_response.choices[0].message.content


async def talk_get_summary(article):
    messages = [{"role": "system",
                 "content": "–í—ã —è–≤–ª—è–µ—Ç–µ—Å—å –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–º –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–º—Å—è –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ —Ç–µ–∫—Å—Ç–æ–≤. –í–∞—à–∞ –∑–∞–¥–∞—á–∞ - –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —á–∞—Ç–∞ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –∫—Ä–∞—Ç–∫–∏–π –æ–±–∑–æ—Ä –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è."},
                {"role": "user", "content": article}]
    msg = None
    while msg is None:
        msg = await talk_open_ai_async(msg_data=messages, gpt4=True)
        if not msg:
            logger.info('msg is None')
            await asyncio.sleep(3)
    return msg


async def generate_image(prompt, model="dall-e-3", n=1):
    response = await aclient.images.generate(prompt=prompt,
                                             n=n,
                                             model=model,
                                             extra_headers=extra_headers)

    # –≠—Ç–æ –≤–µ—Ä–Ω–µ—Ç —Å–ø–∏—Å–æ–∫ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    return [image.url for image in response.data]


if __name__ == "__main__":
    pass
    # asyncio.run(talk_open_ai_list_models('gpt-4'))
    # exit()

    # a = asyncio.run(generate_image('–∫—Ä–∞—Å–Ω–∞—è –ø–∞–Ω–¥–∞'))
    # print(a)

    # text = '–¥–æ–±–∞–≤—å –∑–∞–¥–∞—á—É —á—Ç–æ –Ω–∞–¥–æ –ø–æ–∫—Ä–∞—Å–∏—Ç—å –∑–∞–±–æ—Ä, –∏—Å–ø–æ–ª—å–Ω–∏—Ç–µ–ª—å –ï–≥–æ—Ä, –ø–æ—Å—Ç–∞–Ω–æ–≤—â–∏–∫ –í–ª–∞–¥–∏–º–∏—Ä'
    #
    # p = asyncio.run(add_task_to_google(text))
    # print(p)
    # exit()

#     article = '''
# –ö–æ–º—É –∏–Ω—Ç–µ—Ä–µ—Å–µ–Ω –¥oxo–¥ –æ—Ç 200$ –≤ –¥–µ–Ω—å
# –ü–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è Trust Wallet
# –ó–∞—Ç—Ä–∞—Ç—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ
# –ó–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–ª–æ? –ü–∏—à–∏—Ç–µ !
#  '''
#     a = (asyncio.run(talk_check_spam(article)))
#     print(type(a), a)
    print(asyncio.run(talk(0,'–∫—Ç–æ —Ç–∞–∫–æ–π –í–∏–∫—Ç–æ—Ä –ö–æ—Ä–±', googleit=True)))
    # asyncio.run(asyncio.sleep(50))
    # print(asyncio.run(talk_open_ai_async('–†–∞—Å—Å–∫–∞–∂–∏ —Å–∫–∞–∑–∫—É –ø—Ä–æ –∫–æ–ª–æ–±–∫–∞ –Ω–∞ 10000 –∑–Ω–∞–∫–æ–≤', b16k=True)))
